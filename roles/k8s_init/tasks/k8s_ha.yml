---
- name: install etcd
  yum: name={{ item }} state=present
  with_items:
      - etcd
      - expect
  when:  inventory_hostname in groups["commander"]

- name: copy etc_make_mirror scripts
  copy: src=do_make_mirror.exp dest={{ k8s_temp_dir }} owner=root mode=754
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: copy etc_make_mirror scripts
  template: src=etcd.sh dest={{ k8s_temp_dir }} owner=root mode=754
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: check all pods is running
  shell: source $HOME/.bash_profile && test `kubectl get pods -n kube-system |grep -v Running |wc -l` -eq 1
  register: result
  until: result.rc == 0
  retries: 50
  delay: 10
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: stop apiserver and do etcd_make_mirror scripts
  shell: mv /etc/kubernetes/manifests/kube-apiserver.yaml /etc/kubernetes/ && sleep 10 && cd {{ k8s_temp_dir }} && ./do_make_mirror.exp
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: change port in kube-apiserver.yaml
  shell: sed -i 's/127.0.0.1:2379/127\.0\.0\.1:{{ etcd_port }}/' /etc/kubernetes/kube-apiserver.yaml && mv /etc/kubernetes/kube-apiserver.yaml /etc/kubernetes/manifests/
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: wait for apiserver
  wait_for: host={{ inventory_hostname }} port=6443 delay=10
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: stop singel etcd
  shell: mv /etc/kubernetes/manifests/etcd.yaml /etc/kubernetes/ 
  when:  inventory_hostname in groups["commander"]
  tags: test

- name:  make python simplehttpserver for get pki files
  shell: cd /etc/kubernetes/ && nohup python -m SimpleHTTPServer 18888 &
  when:  inventory_hostname in groups["commander"]
  tags: testapi

- name: wait for simplehttpserver
  wait_for: host={{ inventory_hostname }} port=18888 delay=10
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: wait for simplehttpserver
  shell: sleep 10
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: download pki files
  get_url: 
      url: http://{{ groups["commander"][0] }}:18888/{{ item }}
      dest: /etc/kubernetes/pki/
  with_items:
        - pki/apiserver.crt
        - pki/apiserver.key
        - pki/apiserver-kubelet-client.crt
        - pki/apiserver-kubelet-client.key
        - pki/ca.key
        - pki/front-proxy-ca.crt
        - pki/front-proxy-ca.key
        - pki/front-proxy-client.crt
        - pki/front-proxy-client.key
        - pki/sa.key
        - pki/sa.pub
  when:  inventory_hostname in groups["slave"]
  tags: testapid

- name: download conf files
  get_url: 
      url: http://{{ groups["commander"][0] }}:18888/{{ item }}
      dest: /etc/kubernetes/
  with_items:
        - admin.conf
        - controller-manager.conf
        - scheduler.conf
        - manifests/kube-apiserver.yaml
        - manifests/kube-controller-manager.yaml
        - manifests/kube-scheduler.yaml
  when:  inventory_hostname in groups["slave"]
  tags: testapid

- name: stop python simpleserver
  shell: kill `ps -ef |grep SimpleHTTPServer |awk '{print $2}'`
  ignore_errors: True
  when:  inventory_hostname in groups["commander"]
  tags: testapi


# =======
# cp pki/*
# openssl x509
#   579  openssl genrsa -out apiserver-kube4.key 2048
#     580  openssl req -new -key apiserver-kube4.key -subj "/CN=kube-apiserver," -out apiserver-kube4.csr
#       589  vim apiserver-kube4.ext
#       subjectAltName = DNS:wudang,DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, IP:10.96.0.1, IP:10.9.5.70
#
#         603   openssl x509 -req -in apiserver-kube4.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out apiserver-kube4.crt -days 365 -extfile apiserver-kube4.ext
#
# cp api.yaml to slaves and eidt it(key,crt)
# then check api status
#============
#edit /etc/kubernetes/kubelet.conf;server: https://10.9.5.105:6443 
#systemctl daemon-reload  restart kubelet
#cp kube-scheduler.yaml  kube-controller-manager.yaml and conf file
#kubectl label node kube4 node-role.kubernetes.io/master
#kubectl taint nodes kube5 node-role.kubernetes.io/master=:NoSchedule
#nginx lb and keepalive
#kubectl get configmap/kube-proxy -n kube-system -o yam   and edit
#the restart it 
#=====================
# restart kubectl proxy : kubectl proxy ok?
