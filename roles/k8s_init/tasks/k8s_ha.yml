---
- name: install etcd expect screen
  yum: name={{ item }} state=present
  with_items:
      - etcd
      - expect
      - screen
  when:  inventory_hostname in groups["commander"]

- name: install nginx keepalive
  yum: name={{ item }} state=present
  with_items:
      - keepalived
  when:  inventory_hostname in groups["master"]

- name: copy etc_make_mirror scripts
  copy: src=do_make_mirror.exp dest={{ k8s_temp_dir }} owner=root mode=754
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: copy etc_make_mirror scripts
  template: src=etcd.sh dest={{ k8s_temp_dir }} owner=root mode=754
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: check all pods are running __WARNING__ if too many pods in ContainerCreating, you can download docker images first, and then rerun it
  shell: source $HOME/.bash_profile && test `kubectl get pods -n kube-system |grep -v Running |wc -l` -eq 1
  register: result
  until: result.rc == 0
  retries: 60
  delay: 20
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: stop apiserver and do etcd_make_mirror scripts
  shell: mv /etc/kubernetes/manifests/kube-apiserver.yaml /etc/kubernetes/ && sleep 10 && cd {{ k8s_temp_dir }} && ./do_make_mirror.exp
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: change port in kube-apiserver.yaml
  shell: sed -i 's/127.0.0.1:2379/127\.0\.0\.1:{{ etcd_port }}/' /etc/kubernetes/kube-apiserver.yaml && mv /etc/kubernetes/kube-apiserver.yaml /etc/kubernetes/manifests/
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: wait for apiserver
  wait_for: host={{ inventory_hostname }} port={{ k8s_api_vip_port }} delay=10
  when:  inventory_hostname in groups["commander"]
  tags: test

- name: stop singel etcd
  shell: mv /etc/kubernetes/manifests/etcd.yaml /etc/kubernetes/ 
  when:  inventory_hostname in groups["commander"]
  tags: test

- name:  make python simplehttpserver for get pki files
  shell: cd /etc/kubernetes/ && screen -L -d -m python -m SimpleHTTPServer 18888 
  when:  inventory_hostname in groups["commander"]
  tags: testapi

- name: wait for simplehttpserver
  wait_for: host={{ inventory_hostname }} port=18888 delay=10
  when:  inventory_hostname in groups["commander"]
  tags: testapi

- name: download pki files
  get_url:
      url: http://{{ groups["commander"][0] }}:18888/{{ item }}
      dest: /etc/kubernetes/pki/
      mode: 0600
  with_items:
        - pki/apiserver.crt
        - pki/apiserver.key
        - pki/apiserver-kubelet-client.crt
        - pki/apiserver-kubelet-client.key
        - pki/ca.key
        - pki/front-proxy-ca.crt
        - pki/front-proxy-ca.key
        - pki/front-proxy-client.crt
        - pki/front-proxy-client.key
        - pki/sa.key
        - pki/sa.pub
  when:  inventory_hostname in groups["slave"]
  tags: testapi

- name: download conf files
  get_url: 
      url: http://{{ groups["commander"][0] }}:18888/{{ item }}
      dest: /etc/kubernetes/
  with_items:
        - admin.conf
        - controller-manager.conf
        - scheduler.conf
        - manifests/kube-apiserver.yaml
        - manifests/kube-controller-manager.yaml
        - manifests/kube-scheduler.yaml
  when:  inventory_hostname in groups["slave"]
  tags: testapi

- name: stop python simpleserver
  shell: kill `ps -ef |grep SimpleHTTPServer |awk '{print $2}'`
  ignore_errors: True
  when:  inventory_hostname in groups["commander"]
  tags: testapi

- name: create pki files 
  shell: cd /etc/kubernetes/pki/ && openssl genrsa -out apiserver-{{ inventory_hostname }}.key 2048 && openssl req -new -key apiserver-{{ inventory_hostname }}.key -subj "/CN=kube-apiserver," -out apiserver-{{ inventory_hostname }}.csr
  when:  inventory_hostname in groups["master"]
  tags: createpki

- name: create extfile
  template: src=apiserver-extfile.ext dest=/etc/kubernetes/pki/ owner=root mode=600
  when:  inventory_hostname in groups["master"]
  tags: createpki

- name: create crt file
  shell: cd /etc/kubernetes/pki/ && openssl x509 -req -in apiserver-{{ inventory_hostname }}.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out apiserver-{{ inventory_hostname }}.crt -days 365 -extfile apiserver-extfile.ext
  when:  inventory_hostname in groups["master"]
  tags: createpki

- name: change key files in apiserver.yaml
  shell: sed -i 's/apiserver.key/apiserver-{{ inventory_hostname }}\.key/' /etc/kubernetes/kube-apiserver.yaml 
  when:  inventory_hostname in groups["slave"]
  tags: createpki

- name: change key files in apiserver.yaml
  shell: sed -i 's/apiserver.crt/apiserver-{{ inventory_hostname  }}\.crt/' /etc/kubernetes/kube-apiserver.yaml 
  when:  inventory_hostname in groups["slave"]
  tags: createpki

- name: change advertise-address in apiserver.yaml and start apiserver on localhost
  shell: sed -i 's/{{ k8s_api_vip }}/{{ ansible_default_ipv4.address  }}/' /etc/kubernetes/kube-apiserver.yaml && sed -i 's/{{ k8s_api_vip_port }}/6443/' /etc/kubernetes/kube-apiserver.yaml && mv /etc/kubernetes/kube-apiserver.yaml /etc/kubernetes/manifests/
  when:  inventory_hostname in groups["slave"]
  tags: createpki

- name: check all pods are running
  shell: source $HOME/.bash_profile && test `kubectl get pods -n kube-system |grep -v Running |wc -l` -eq 1
  register: result
  until: result.rc == 0
  retries: 50
  delay: 10
  when:  inventory_hostname in groups["commander"]
  tags: createpki

- name: change apiserver in commander
  shell: mv /etc/kubernetes/manifests/kube-apiserver.yaml /etc/kubernetes/ && sed -i 's/apiserver.key/apiserver-{{ inventory_hostname }}\.key/' /etc/kubernetes/kube-apiserver.yaml &&  sed -i 's/apiserver.crt/apiserver-{{ inventory_hostname  }}\.crt/' /etc/kubernetes/kube-apiserver.yaml && sed -i 's/{{ k8s_api_vip_port }}/6443/' /etc/kubernetes/kube-apiserver.yaml && sed -i 's/{{ k8s_api_vip }}/{{ ansible_default_ipv4.address }}/' /etc/kubernetes/kube-apiserver.yaml && mv /etc/kubernetes/kube-apiserver.yaml /etc/kubernetes/manifests/ 
  when:  inventory_hostname in groups["commander"]
  tags: createpki-test

- name: copy admin.conf
  shell: sed -i 's/server.*{{ k8s_api_vip_port }}/server\:\ https\:\/\/{{ inventory_hostname }}:6443/' /etc/kubernetes/admin.conf && cp /etc/kubernetes/admin.conf $HOME && chmod 600 $HOME/admin.conf
  when:  inventory_hostname in groups["commander"]
  tags: createpi-test

- name: check all pods are running
  shell: source $HOME/.bash_profile && test `kubectl get pods -n kube-system |grep -v Running |wc -l` -eq 1
  register: result
  until: result.rc == 0
  retries: 50
  delay: 10
  when:  inventory_hostname in groups["commander"]
  tags: createpki-test

# ======
- name: install nginx repo
  template: src=nginx.repo dest=/etc/yum.repos.d/ owner=root mode=650
  when:  inventory_hostname in groups["master"]
  tags: nginx

- name: install nginx pkg
  yum: name=nginx enablerepo=nginx
  when:  inventory_hostname in groups["master"]
  tags: nginx

- name: copy nginx.conf
  template: src=nginx.conf dest=/etc/nginx/ owner=root mode=644
  when:  inventory_hostname in groups["master"]
  tags: nginx

- name: start nginx
  service: name=nginx state=restarted enabled=yes
  when:  inventory_hostname in groups["master"]
  tags: nginx

- name: change apiserver address in scheduler.conf
  shell: mv /etc/kubernetes/kube-scheduler.yaml /etc/kubernetes/manifests
  when:  inventory_hostname in groups["slave"]
  tags: scheduler

- name: check all scheduler are running
  shell: source $HOME/.bash_profile && test `kubectl get pods -n kube-system |grep scheduler |grep -v Running | wc -l` -eq 0
  register: result
  until: result.rc == 0
  retries: 50
  delay: 10
  when:  inventory_hostname in groups["commander"]
  tags: scheduler

# ======
- name: change apiserver address in controller-manager.conf.conf
  shell: mv /etc/kubernetes/kube-controller-manager.yaml /etc/kubernetes/manifests
  when:  inventory_hostname in groups["slave"]
  tags: controller-manager

- name: check all controller-manager are running
  shell: source $HOME/.bash_profile && test `kubectl get pods -n kube-system |grep controller-manager |grep -v Running | wc -l` -eq 0
  register: result
  until: result.rc == 0
  retries: 50
  delay: 10
  when:  inventory_hostname in groups["commander"]
  tags: controller-manager
# =======
- name: copy admin.conf
  shell: cp /etc/kubernetes/admin.conf $HOME && chmod 600 $HOME/admin.conf
  when:  inventory_hostname in groups["slave"]
  tags: label-master

- name: set bash_profile
  shell: echo 'export KUBECONFIG=$HOME/admin.conf' >> $HOME/.bash_profile 
  when:  inventory_hostname in groups["slave"]
  tags: label-master

#k8s_master_scheduled: true
- name: label node noschedule
  shell: source $HOME/.bash_profile && kubectl label node {{ inventory_hostname }} node-role.kubernetes.io/master=
  when:  inventory_hostname in groups["slave"] and k8s_master_scheduled != true
  tags: label-master

- name: taint node
  shell: source $HOME/.bash_profile && kubectl taint node {{ inventory_hostname }} node-role.kubernetes.io/master=:NoSchedule
  when:  inventory_hostname in groups["slave"] and k8s_master_scheduled != true
  tags: label-master

- name: config keepalived
  template: src=keepalived.conf dest=/etc/keepalived/ mode=644
  when:  inventory_hostname in groups["master"]
  tags: ka

- name: start keepalived
  service: name=keepalived state=restarted enabled=yes
  when:  inventory_hostname in groups["master"]
  tags: ka

#update hosts file (kubernetes.default)
- name: add record to hosts
  shell: echo "{{ hostvars[groups['commander'][0]]['k8s_api_vip'] }}   kubernetes.default.svc " >> /etc/hosts
  tags: hosts


#- name: apply kube-proxy.configmap
#  shell: source $HOME/.bash_profile && kubectl apply -f {{ k8s_temp_dir }}/kube-proxy.configmap
#  when:  inventory_hostname in groups["commander"]
#  tags: kube-proxy
#
#- name: restart kube-proxy
#  shell: source $HOME/.bash_profile && kubectl get pods -n kube-system |grep kube-proxy |awk '{ print $1}' |while read line;do echo kubectl delete pods/$line -n kube-system; sleep 5;done
#  when:  inventory_hostname in groups["commander"]
#  tags: kube-proxy
#
#
- name: scale kube-dns
  shell: source $HOME/.bash_profile && kubectl scale deploy/kube-dns  --replicas=3 -n kube-system
  when:  inventory_hostname in groups["commander"]

#######
